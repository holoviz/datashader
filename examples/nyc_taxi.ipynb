{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting very large datasets meaningfully, using `datashader`\n",
    "\n",
    "There are a variety of approaches for plotting large datasets, but most of them are very unsatisfactory. Here we first show some of the issues, then demonstrate how the `datashader` library helps make large datasets truly practical.  \n",
    "\n",
    "We'll use part of the well-studied [NYC Taxi trip database](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml), with the locations of all NYC taxi pickups and dropoffs from the month of January 2015.  Although we know what the data is, let's approach it as if we are doing data mining, and see what it takes to understand the dataset from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load NYC Taxi data \n",
    "\n",
    "(takes a dozen seconds or so, since it's in a fairly inefficient CSV file format...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/nyc_taxi.csv',usecols=['pickup_x','pickup_y','dropoff_x','dropoff_y','passenger_count'])\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this file contains about 12 million pickup and dropoff locations (in Web Mercator coordinates), with passenger counts.\n",
    "\n",
    "## Define a simple plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "x_range=(-8250000,-8210000)\n",
    "y_range=(4965000,4990000)\n",
    "\n",
    "def base_plot(tools='pan,wheel_zoom,reset',webgl=False):\n",
    "    p = figure(\n",
    "        tools=tools,\n",
    "        plot_width=900,\n",
    "        plot_height=600,\n",
    "        responsive=True,\n",
    "        x_range=x_range,\n",
    "        y_range=y_range,\n",
    "        outline_line_color=None,\n",
    "        min_border=0,\n",
    "        webgl=webgl)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    return p\n",
    "    \n",
    "options = dict(line_color=None, fill_color='blue', size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1000-point scatterplot: undersampling\n",
    "\n",
    "Any plotting program should be able to handle a plot of 1000 datapoints.  Here the points are initially overplotting each other, but if you hit the Reset button (top right of plot) to zoom in a bit, each of them should be clearly visible in the following Bokeh plot of a random 1000-point sample.  If you know what to look for, you can even see the outline of Manhattan Island and Central Park from the pattern of dots.  We've included geographic map data here to help get you situated, though for a genuine data mining task you might not have any such landmarks.  Because this plot is discarding 99.99% of the data, it reveals very little of what might be contained in the dataset, a problem called *undersampling*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from bokeh.tile_providers import STAMEN_TERRAIN\n",
    "\n",
    "samples = df.sample(n=1000)\n",
    "p = base_plot()\n",
    "p.add_tile(STAMEN_TERRAIN)\n",
    "p.circle(x=samples['dropoff_x'], y=samples['dropoff_y'], **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10,000-point scatterplot: overplotting\n",
    "\n",
    "We can of course plot more points to reduce the amount of undersampling, but even if we try to plot only 0.1% of the data, we will find major problems with *overplotting*, such that the true density of dropoffs in central Manhattan is impossible to see due to occlusion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "samples = df.sample(n=10000)\n",
    "p = base_plot()\n",
    "\n",
    "p.circle(x=samples['dropoff_x'], y=samples['dropoff_y'], **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overplotting is reduced if you zoom in on a particular region (may need to click to enable the wheel-zoom tool in the upper right of the plot first, then use the scroll wheel).  However, then the problem switches to back to serious undersampling, as the too-sparsely sampled datapoints get revealed for zoomed-in regions, even though much more data is available.\n",
    "\n",
    "## 100,000-point scatterplot: saturation\n",
    "\n",
    "If you make the dot size smaller, you can reduce the overplotting that occurs when you try to combat undersampling.  Even so, with enough opaque data points, overplotting will be unavoidable in popular dropoff locations.  So you can then adjust the alpha (opacity) parameter of most plotting programs, so that multiple points need to overlap before full color saturation is achieved.  With enough data, such a plot can approximate the probability density function for dropoffs, showing where dropoffs were most common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "options = dict(line_color=None, fill_color='blue', size=1, alpha=0.1)\n",
    "samples = df.sample(n=100000)\n",
    "p = base_plot(webgl=True)\n",
    "p.circle(x=samples['dropoff_x'], y=samples['dropoff_y'], **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it's very tricky to set the size and alpha parameters.  How do we know if certain regions are saturating, unable to show peaks in dropoff density? Here we've manually set the alpha to show a clear structure of streets and blocks, as one would intuitively expect to see, but the density of dropoffs still seems approximately the same on all Manhattan streets (just wider in some locations), which is unlikely to be true. We can of course reduce the alpha value to reduce saturation further, but there's no way to tell when it's been set correctly, and it's already low enough that nothing other than Manhattan is showing up at all. Plus, this alpha value will only work even reasonably well at the one zoom level shown. Try zooming in (may need to enable the wheel zoom tool in the upper right) to see that at higher zooms, there is less overlap between dropoff locations, so that the points *all* start to become transparent due to lack of overlap. Yet without setting the size and alpha to a low value in the first place, the stucture is invisible when zoomed out, due to overplotting. Thus even though Bokeh provides rich support for interactively revealing structure by zooming, it is of limited utility for large data; either the data is invisible when zoomed in, or there's no large-scale structure when zoomed out, which is necessary to indicate where zooming would be informative.\n",
    "\n",
    "Moreover, we're still ignoring 99% of the data.  Many plotting programs will have trouble with plots even this large, but Bokeh can handle 100-200,000 points in most browsers. Here we've enabled Bokeh's WebGL support, which gives smoother zooming behavior, but the non-WebGL mode also works well. Still, for such large sizes the plots become slow due to the large HTML file sizes involved, because each of the data points are encoded as text in the web page, and for even larger samples the browser will fail to render the page at all.  \n",
    "\n",
    "\n",
    "## 10-million-point datashaded plots: auto-ranging, but not perceptually calibrated\n",
    "\n",
    "To let us work with truly large datasets without discarding most of the data, we can take a different approach. Instead of using a Bokeh scatterplot, which encodes every point into JSON and stores it in the HTML file read by the browser, we can use the [`datashader`](https://github.com/bokeh/datashader) library to render the entire dataset into a pixel buffer in a separate Python process, and then provide a fixed-size image to the browser, containing only the data currently visible. This approach decouples the data processing, which is then limited only by the computational power available, from the visualization, which is limited by your display device (a web browser in this case).\n",
    "\n",
    "The steps involved in datashading are (1) create a Canvas object with the shape of the eventual plot (i.e. having one storage bin for collecting points, per final pixel), (2) aggregating all points into that set of bins, incrementally counting them, and (3) mapping the resulting counts into a visible color from a specified range, to build an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from datashader import transfer_functions as tf\n",
    "from functools import partial\n",
    "\n",
    "def create_image(x_range, y_range, w, h, color_fn=tf.interpolate):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    agg = cvs.points(df, 'dropoff_x',  'dropoff_y',  ds.count('passenger_count'))\n",
    "    image = color_fn(agg)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Because the number of points involved is no longer a limiting factor, you can use the entire dataset (including the full 150 million trips that have been made public, if you download that data separately).  Moreover, datashader allows computation on the intermediate stages of plotting, which lets you easily define operations like auto-ranging (which is on by default), so that we can be sure there is no overplotting or saturation and no need to set an alpha parameter. \n",
    "\n",
    "However, when we try it, we can see that the results from this naive approach are unsatisfying, and little better than the 100,000-point Bokeh plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "create_image(x_range, y_range, 800, 500, color_fn=partial(tf.interpolate, low=\"white\", high='darkblue', how='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the plot above we can clearly see a peak in dropoffs around Penn Station, Madison Square Garden, and Times Square, as one might expect, and we know there is no saturation because of datashader's default auto-ranging.  Yet very little of the other structure of the dataset is visible -- e.g. most areas of this image *appear* to have no dropoffs. To see if that's really true, let's set the color for pixels that have at least one dropoff as a light color, and then interpolate from there for higher values.  With datashading, it's easy to do that, because one can express computations not just on the data, but on the visualization.  In the resulting plot (below), it is obvious that most areas *do* have dropoffs, and that there is rich structure in this data.  But the result is still quite unsatisfactory -- most regions of Manhattan seem to be nearly uniformly densely populated with dropoffs, apart from the very largest Penn Station peak and some dimly visible street outlines: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image(x_range, y_range,800, 500, color_fn=partial(tf.interpolate, low=\"lightblue\", high='darkblue', how='linear'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-million-point datashaded plots: perceptually calibrated, and interactive\n",
    "\n",
    "The key limitation of the above datashaded plots is that they use linear scaling between counts and the colors shown on screen.  Our visual systems do not perceive linear color ramps linearly, and so we cannot see much of the structure present in such plots.  Instead, we need to use nonlinear scaling, such as a log or cube root function mapping from the number of counts into the color ramp.  The datashader default is to use cube root scaling, which is why the above plots had to specify \"linear\" explicitly.  Here we'll use the cube root default, and we'll also embed the generated images into a Bokeh plot to support fully interactive zooming:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datashader as ds\n",
    "from datashader.callbacks import InteractiveImage\n",
    "\n",
    "p = base_plot()\n",
    "InteractiveImage(p, create_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Finally, the full structure of the data is visible, and it's actually easier to use than all of the previous steps, because no parameters are required in most cases.  Just provide the data to plot, and datashader will accurately reveal it to the observer.  Here there are now clearly more dropoffs on streets than on non-street areas, and this structure is visible both in central Manhattan (where there are clearly many more dropoffs total) and in the surrounding regions.  There are also some clear problems with the quality of the data -- there are a significant number of trips that claim to drop off in the water or in the roadless areas of Central park, as well as in the middle of most of the tallest buildings in central Manhattan. These locations are likely to be GPS errors being made visible, perhaps partly because of poor GPS performance in between the tallest buildings.\n",
    "\n",
    "Note that you can zoom in interactively to this plot, seeing all the points available in that viewport, without ever needing to change the plot parameters.  Each time you zoom or pan, a new image is rendered (which takes a few seconds for large datasets), and displayed overlaid the other plot elements, providing full access to all of your data.\n",
    "\n",
    "## Customizing datashader\n",
    "\n",
    "Each of the stages of the datashader pipeline can be changed, either for personal preferences or to highlight specific aspects of the data.  E.g. you can map the counts into a different set of colors.  Here we replace `create_image` with a user-customizable `Pipeline` object that encapsulates this common series of processing steps, making it easy to create an interactive plot from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p = base_plot()\n",
    "pipeline = ds.Pipeline(df, ds.Point(\"dropoff_x\", \"dropoff_y\"), agg=ds.count(\"passenger_count\"),\n",
    "                       color_fn=partial(tf.interpolate,low=\"lightpink\",high=\"darkred\"))\n",
    "InteractiveImage(p, pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can arbitrarily specify each of these steps, to do novel operations once your data has been aggregated into pixel-shaped bins -- computations on the visualization, not just the data!  For instance, you might want to plot all the pixels where there were more dropoffs than pickups in blue, and all those where there were more pickups than dropoffs in red.  To do this, just write your own function that will create an image, when given x and y ranges, a resolution (w x h), and zero or more optional arguments.  You can then either call it yourself, or pass it to `InteractiveImage` to make an interactive plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def create_image(x_range, y_range, w, h, how='log'):\n",
    "    cvs = ds.Canvas(plot_width=w, plot_height=h, x_range=x_range, y_range=y_range)\n",
    "    picks = cvs.points(df, 'pickup_x',  'pickup_y',  ds.count('passenger_count'))\n",
    "    drops = cvs.points(df, 'dropoff_x', 'dropoff_y', ds.count('passenger_count'))\n",
    "    more_drops = tf.interpolate(drops.where(drops > picks), \"lightblue\", 'blue', how=how)\n",
    "    more_picks = tf.interpolate(picks.where(picks > drops), \"lightpink\", 'red',  how=how)\n",
    "    return tf.stack(more_picks,more_drops)\n",
    "\n",
    "p = base_plot()\n",
    "InteractiveImage(p, create_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now you can see that pickups are more common on major roads, as you'd expect, and dropoffs are more common on side streets.  In Manhattan, roads running along the island are more common for pickups. If you zoom in to any location, the data will be re-aggregated to the new resolution automatically, again calculating for each pixel whether pickups or dropoffs were more likely. The interactive features of Bokeh are now fully usable with this large dataset, allowing you to uncover new structure at every level. \n",
    "\n",
    "The above example just used pre-existing components provided for the datashader pipeline, but you can implement any components you like and substitute them, allowing you to easily explore and highlight specific aspects of your data. Have fun datashading!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
